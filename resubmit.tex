\documentclass[11pt]{article}
\usepackage{epsfig}
\usepackage{subfigure}
\usepackage{setspace}
\usepackage{url}

\setlength{\textheight}{8.875in} \setlength{\textwidth}{6.5in}
\setlength{\topmargin}{0.0in} \setlength{\headheight}{0.0in}
\setlength{\headsep}{0.0in} \setlength{\oddsidemargin}{0.0in}

\begin{document}
\pagestyle{plain}
\thispagestyle{plain}

\begin{center}
\textbf{\Large Resubmission Change Description}
\end{center}

This document articulates the changes made to the current submission relative
to the SBIR submission last year under the same title.

The changes, including relevant comments from reviewers (where pertinent)
are as follows:

\begin{enumerate}

\item The previous submission was under the SBIR program, which has strict
limits of relative effort for the small business and any research institution
that is a subawardee.  For this submission, we have opted to propose to the
STTR program, for which the relative effort limitations allow a greater effort
on the part of the research institution.  This action was
taken in direct support of item 2. below, adding another university
researcher to the team.

\item The strongest reviewer feedback that we received was a concern that
there didn't exist a differential privacy expert on the team.  We have taken
this concern to heart, and this year's proposal includes Dr.~Yevgeniy
Vorobeychik, Assoc.~Professor of Computer Science and Engineering at
Washington University in St.~Louis.  Dr.~Vorobeychik's research includes
privacy risk analysis in data sharing settings, using game theory to
reason about an adversary's behavior.
He has investigated privacy-preserving data sharing techniques
in the context of HIPPA-protected biomedical data.

\item One reviewer commented that Uber released an open source project
on differential privacy in July 2017 (after submission of the previous
proposal), and that the Uber project could potentially be a competitor.
We have cited the Uber project in this submission, and we respectfully
disagree with the reviewer that it would be competitive with our proposal.
Rather, we believe it is complimentary (as explained in the text of the
proposal), decreasing the effort required to implement differential
privacy mechanisms and increasing the time available for assessment of
their efficacy.

\item In response to several reviewers comments concerning the investigation
of privacy techniques, we have altered the text of the proposal in several
places to reflect the following. First, we attempt to make clear that
both the company and end users will have access to the differentially
private data, enabling learning (both human- and machine-) to happen
in each of these organizations. What BECS learns (e.g., in Phase~II)
will be shared with its customers. What individual customers learn is
theirs to decide with whom to share.  Second, we have been more explicit
as to how we intend to approach the limitations of differential privacy
for multi-dimensional data.

\item We have altered the description of the visualization research to
be more concrete in the specific actions that we will take.  Here, we are
not attempting to create \emph{new} visualizations.  Rather, we are trying
to determine what visualization techniques are most effective in the
context of understanding uncertainty specifically due to differential
privacy mechanisms.

\end{enumerate}

\end{document}
